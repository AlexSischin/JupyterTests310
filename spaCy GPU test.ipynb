{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83da4345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:51:39.528578: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-30 17:51:40.252528: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-05-30 17:51:41.091694: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-30 17:51:41.095693: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-30 17:51:41.095727: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and being used by SpaCy\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "if spacy.require_gpu():\n",
    "    print(\"GPU is available and being used by SpaCy\")\n",
    "else:\n",
    "    print(\"GPU is not being used by SpaCy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ec8025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.35658795 1.11741288 1.27547725 ... 1.20467084 1.4141815  1.40907389]\n",
      " [1.32106028 1.41400743 1.41334304 ... 1.2485858  1.15324436 1.40316303]\n",
      " [1.40228054 1.41387887 1.3984469  ... 1.00532433 1.33745478 1.38578192]\n",
      " ...\n",
      " [1.17033013 1.07725698 1.07254289 ... 1.41343266 1.30680035 1.29697091]\n",
      " [1.41275781 1.25629606 1.37270043 ... 1.41315782 1.38805216 1.0529424 ]\n",
      " [1.41215084 1.30688538 1.40787725 ... 1.25585193 1.35366125 1.10743965]]\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "\n",
    "# Create a random array on GPU\n",
    "x_gpu = cp.random.random((1000, 1000))\n",
    "\n",
    "# Perform some computations on the GPU\n",
    "y_gpu = cp.sin(x_gpu) + cp.cos(x_gpu)\n",
    "\n",
    "# Transfer the result back to the CPU\n",
    "y_cpu = cp.asnumpy(y_gpu)\n",
    "\n",
    "# Verify the results\n",
    "print(y_cpu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
